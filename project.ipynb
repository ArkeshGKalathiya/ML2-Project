{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/arkeshkalathiya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/arkeshkalathiya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/arkeshkalathiya/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "### download necessary data\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltkStopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explanation\n",
      "why the edits made under my username hardcore metallica fan were reverted? they weren't vandalisms, just closure on some gas after i voted at new york dolls fac. and please don't remove the template from the talk page since i'm retired now.89.205.38.27\n",
      "\n",
      "\n",
      "explanation why the edits made under my username hardcore metallica fan were reverted they werent vandalism just closure on some gas after i voted at new york doll fac and please dont remove the template from the talk page since im retired now\n"
     ]
    }
   ],
   "source": [
    "## load data\n",
    "\n",
    "\n",
    "validWords = set(words.words())\n",
    "\n",
    "\n",
    "def removeNumber(comment):\n",
    "    return re.sub(r'\\d+',\"\",comment)\n",
    "\n",
    "def removeDoubleDots(comment):\n",
    "    return re.sub(r'\\.{2,}',\"\",comment)\n",
    "\n",
    "def removeDoubleSpace(comment):\n",
    "    return re.sub(r'[ ]{2,}',\" \",comment)\n",
    "\n",
    "def removeTalk(comment):\n",
    "    return re.sub(r'\\(talk\\)',\"\",comment)\n",
    "\n",
    "def removePunctuations(comment):\n",
    "    return re.sub(r'[^\\w\\s]','',comment)\n",
    "\n",
    "def removeNewLine(comment):\n",
    "    return re.sub(r'\\n',\" \",comment)\n",
    "\n",
    "def tokenize(comment):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    tokens = [wnl.lemmatize(word) for word in nltk.word_tokenize(comment)]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "data = pd.read_csv('./data/train.csv')\n",
    "\n",
    "\n",
    "with open('./output.csv','w') as outputFile:\n",
    "    for index,row in data.iterrows():\n",
    "\n",
    "        comment = row[\"comment_text\"].lower()\n",
    "        originalComment = comment\n",
    "        \n",
    "        comment = removeNumber(comment)\n",
    "        comment = removeNewLine(comment)\n",
    "        comment = removeTalk(comment)\n",
    "        comment = removeDoubleSpace(comment)\n",
    "        comment = removeDoubleDots(comment)\n",
    "        comment = removePunctuations(comment)\n",
    "        comment = tokenize(comment)\n",
    "        \n",
    "        matches = re.findall(r'[0-9]+',comment)\n",
    "        print(originalComment)\n",
    "        print(\"\\n\")\n",
    "        print(comment)\n",
    "        break\n",
    "                # print(word)\n",
    "                # break\n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
